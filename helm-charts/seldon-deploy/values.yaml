
replicaCount: 1

#in RH marketplace images will come from RH hosting through an override in CSV - default to dockerhub ubi images
image:
  image: seldonio/seldon-deploy-server-ubi:1.2.0
  pullPolicy: Always

#uncomment below to use imagePullSecrets e.g. to avoid docker rate-limiting
# imagePullSecrets:
#  - name: regcred

loadtest:
  image: seldonio/hey-loadtester-ubi:0.1

alibidetect:
  image: seldonio/alibi-detect-server:1.7.0

nameOverride: ""
fullnameOverride: ""

service:
  type: ClusterIP
  port: 80

# Default user id to add to all Pod Security Context as the default
# Use this to ensure all container run as non-root by default
# For openshift leave blank as usually this will be injected automatically on an openshift cluster
# to all pods.
defaultUserID: ""

# boolean to enable app-level auth (defaults to "false")
enableAppAuth: false

# boolean to enable app-analytics (defaults to "true")
enableAppAnalytics: false

env:
  USERID_CLAIM_KEY: "name" # claim to be used as userid (defaults to "preferred_username")
  # if using app level auth then set below env vars
  # OIDC_PROVIDER oidc providerURL
  # CLIENT_ID oidc client ID
  # CLIENT_SECRET oidc client secret
  # REDIRECT_URL  `${oidc_redirect_url}/seldon-deploy/auth/callback`
  # OIDC_SCOPES oidc scopes (defaults to "profile email groups")
  # RESOURCE_URI resourceURI
  # if enableAppAnalytics enabled use token
  # APP_ANALYTICS_TOKEN: ""

docker:
  user: "unknown"

ingress:
  enabled: false
  annotations: {}
  # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []

  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources:
  limits:
    cpu: 800m
    memory: 800Mi
  requests:
    cpu: 100m
    memory: 200Mi

serviceAccount:
  create: true

gitops:
  git:
    secret: "git-creds"
    #user, token and email can be blank if secret is provided
    user: ""
    email: ""
    token: ""
    skipVerifyGit: true
    webhook:
      service:
        create: true
        loadBalancerSourceRanges: {}
  fileFormat: "json"
  argocd:
    enabled: true
    namespace: argocd

batchjobs:
  serviceAccount: "workflow"
  processor:
    image: seldonio/seldon-core-s2i-python37:1.7.0
  mc:
    image: minio/mc:latest
  pvc:
    defaultSize: 1Gi

kfserving:
  protocol: "http"
  enabled: false
  #Below are templates that can be changed to adjust how requests are made and what curl option is shown to user.
  #Change ip to hostname on AWS. Or put real cluster IP after install.
  curlForm: |
    MODEL_NAME={{ .ModelName }}<br>
    CLUSTER_IP=$(oc get route -n {{ .IngressNamespace }} {{ .IngressServiceName }} -o jsonpath='{.spec.host}')<br>
    SERVICE_HOSTNAME=$(kubectl get inferenceservice {{ .ModelName }} -o jsonpath='{.status.url}' | cut -d "/" -f 3)<br>
    curl -v -H "Host: ${SERVICE_HOSTNAME}" {{ .KfServingProtocol }}://$CLUSTER_IP/v1/models/$MODEL_NAME:predict -d '{{ .Payload }}'
  #Form for cluster-internal calls.
  requestForm: "{{ .KfServingProtocol }}://{{ .IngressServiceName }}/v1/models/{{ .ModelName }}:predict"
  explainForm: "{{ .KfServingProtocol }}://{{ .IngressServiceName }}/v1/models/{{ .ModelName }}:explain"

seldon:
  protocol: "http"
  enabled: true
  #Below are templates that can be changed to adjust how requests are made and what curl option is shown to user.
  #Change ip to hostname on AWS. Or put real cluster IP after install. Shown to user for calls outside cluster.
  curlForm: |
    CLUSTER_IP=$(oc get route -n {{ .IngressNamespace }} {{ .IngressServiceName }} -o jsonpath='{.spec.host}')<br>
    curl -k -H "Content-Type: application/json" {{ .SeldonProtocol }}://$CLUSTER_IP/seldon/{{ .Namespace }}/{{ .ModelName }}/api/v0.1/predictions -d '{{ .Payload }}'
  tensorFlowCurlForm: |
    CLUSTER_IP=$(oc get route -n {{ .IngressNamespace }} {{ .IngressServiceName }} -o jsonpath='{.spec.host}')<br>
    curl -k -H "Content-Type: application/json" {{ .SeldonProtocol }}://$CLUSTER_IP/seldon/{{ .Namespace }}/{{ .ModelName }}/v1/models/:predict -d '{{ .Payload }}'
  kfservingV2CurlForm: |
    CLUSTER_IP=$(oc get route -n {{ .IngressNamespace }} {{ .IngressServiceName }} -o jsonpath='{.spec.host}')<br>
    curl -k -H "Content-Type: application/json" {{ .SeldonProtocol }}://$CLUSTER_IP/seldon/{{ .Namespace }}/{{ .ModelName }}/v2/models/{{ .GraphModelName }}/infer -d '{{ .Payload }}'
  #Forms for cluster-internal calls.
  #e.g. could be changed to skip ingress by setting to "http://{{ .ModelName }}-{{ .ModelName }}-{{ .Predictor }}.{{ .Namespace }}:8000/api/v0.1/predictions"
  seldonRequestForm: "{{ .SeldonProtocol }}://{{ .IngressServiceName }}/seldon/{{ .Namespace }}/{{ .ModelName }}/api/v0.1/predictions"
  tensorflowRequestForm: "{{ .SeldonProtocol }}://{{ .IngressServiceName }}/seldon/{{ .Namespace }}/{{ .ModelName }}/v1/models/:predict"
  v2RequestForm: "{{ .SeldonProtocol }}://{{ .IngressServiceName }}/seldon/{{ .Namespace }}/{{ .ModelName }}/v2/models/{{ .ModelName }}/infer"
  #explainer call for seldon can go straight to predictor rather than ingress as not worried about loadbalancing a canary
  explainForm: "http://{{ .ModelName }}-{{ .Predictor }}-explainer.{{ .Namespace }}:9000/v1/models/{{ .ModelName }}:explain"

external:
  protocol: "http"

serviceAccountName: seldon-deploy

ingressGateway:
  seldonIngressService: "istio-ingressgateway"
  kfServingIngressService: "istio-ingressgateway"
  ingressNamespace: "istio-system"

virtualService:
  create: true
  prefix: "/seldon-deploy/"
  gateways:
    - istio-system/seldon-gateway

rbac:
  create: true
  #clusterWide rbac is needed for deploy to see and create resources in different namespaces
  clusterWide: true
  #reading namespaces is needed for single deploy to be used across namespaces, even if rbac gets added for each specific namespace
  #for single namespace mode with just roles, turn off cluserWide and turn off readNamespaces
  readNamespaces: true

nodeSelector: {}

tolerations: []

affinity: {}

skipVerifyHttpCalls: true


prometheus:
  seldon:
    url: "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/"
    # if using community operator then above becomes "http://prometheus-operated.seldon:9090/api/v1/"
    # resource metrics may come from different prometheus than req metrics - set only if different
    resourceMetricsUrl: "https://prometheus-k8s.openshift-monitoring:9091/api/v1/"
    # see https://github.com/openshift/cluster-monitoring-operator/issues/768
    namespaceMetricName: "namespace"
    serviceMetricName: "exported_service"
    #leave below empty/commented for prom without token-based auth
    #basic auth can be handled by putting user:pass in url.
    jwtSecretName: "jwt-seldon"
    jwtSecretKey: "jwt-seldon.txt"
  knative:
    url: "http://prometheus-system-np.knative-monitoring.svc.cluster.local:8080/api/v1/"


elasticsearch:
  url: "https://elasticsearch-seldon-es-http.seldon-logs:9200"
  #enable below for elastic with user and password
  basicAuth: true
  secret:
    name: "elastic-credentials"
    userKey: "username"
    passwordKey: "password"
  #or instead below for token-based auth
  #jwtSecretName: "jwt-seldon"
  #jwtSecretKey: "jwt-seldon.txt"

#only create request logger if you've not already installed it outside of helm (or first delete existing install)
#if namespace.create is false then assumes namespace existing with a knative broker (kubectl get broker -n seldon-logs)
#detectors are created in the namespace requestLogger.namespace.name so rbac is created there
requestLogger:
  create: true
  image: seldonio/seldon-request-logger:1.7.0
  #increase logger replicas if there are high traffic volumes
  replicas: 1
  imagePullPolicy: IfNotPresent
  elasticsearch:
    host: "elasticsearch-seldon-es-http.seldon-logs"
    port: "9200"
    protocol: "https"
#    jwtSecretName: "jwt-seldon"
#    jwtSecretKey: "jwt-seldon.txt"
  namespace:
    create: false
    name: seldon-logs
  trigger:
    apiVersion: "eventing.knative.dev/v1"
    broker: "default"
  resources:
    limits:
      cpu: 600m
      memory: 500Mi
    requests:
      cpu: 100m
      memory: 200Mi

openshiftMarketplace:
  cleanupClusterServiceVersions: false
  kubectlCleanupImage: seldonio/kubectl:1.14.3
  seldonCore:
    subscription:
      create: true
      apiVersion: "operators.coreos.com/v1alpha1"
      channel: "stable"
      metricsPath: "/metrics"
      istioEnabled: true
      requestLoggerEndpoint: "http://broker-ingress.knative-eventing.svc.cluster.local/seldon-logs/default"
    istioGateway:
      create: true
      name: "seldon-gateway"
      namespace: "istio-system"
  prometheus:
    monitorSpecs:
      create: true

metadata:
  pg:
    enabled: false
    secret: "metadata-postgres"
